"""
Module de traitement YouTube - RSS feeds et r√©solution Channel IDs
"""
import subprocess
import feedparser
from datetime import datetime, timedelta


def extract_channel_name(url):
    """Extraire le nom de la cha√Æne depuis l'URL YouTube"""
    try:
        if "@" in url:
            # Format: https://www.youtube.com/@Underscore_
            return url.split("@")[-1]
        elif "/c/" in url:
            # Format: https://www.youtube.com/c/Micode
            return url.split("/c/")[-1]
        elif "/channel/" in url:
            # Format: https://www.youtube.com/channel/UCxxx
            return url.split("/channel/")[-1]
        else:
            # Fallback: prendre la derni√®re partie apr√®s /
            return url.split("/")[-1]
    except (IndexError, AttributeError):
        return url  # Retourner l'URL si extraction √©choue


def get_channel_id_from_url(channel_url):
    """Obtenir l'ID de la cha√Æne depuis son URL YouTube - M√©thode curl/grep"""
    try:
        # Si c'est d√©j√† un ID de cha√Æne
        if channel_url.startswith("UC") and len(channel_url) == 24:
            return channel_url

        # Si c'est une URL avec /channel/
        if "/channel/" in channel_url:
            return channel_url.split("/channel/")[-1].split("?")[0]

        # Utiliser la m√©thode curl/grep qui fonctionne parfaitement
        cmd = f'''curl -sL "{channel_url}" | grep -oE '("channelId"|"externalId"|"ownerChannelId"):"UC[-_0-9A-Za-z]{{22}}' | head -n1 | grep -oE 'UC[-_0-9A-Za-z]{{22}}' '''

        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=30
        )

        if result.returncode == 0 and result.stdout.strip():
            channel_id = result.stdout.strip()
            if channel_id.startswith("UC") and len(channel_id) == 24:
                return channel_id

        print(f"‚ö†Ô∏è Impossible de trouver l'ID pour {channel_url}")
        return None

    except Exception as e:
        print(f"‚ùå Erreur extraction ID cha√Æne {channel_url}: {e}")
        return None


def get_recent_videos_from_rss(channel_url, hours_limit=168):
    """R√©cup√©rer les vid√©os r√©centes via RSS feed YouTube (7 jours par d√©faut)"""
    try:
        # Obtenir l'ID de la cha√Æne
        channel_id = get_channel_id_from_url(channel_url)
        if not channel_id:
            return []

        # Construire l'URL du flux RSS
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"

        # Parser le flux RSS
        feed = feedparser.parse(rss_url)

        if not feed.entries:
            print(f"‚ö†Ô∏è Aucune vid√©o trouv√©e dans le flux RSS pour {channel_url}")
            return []

        # Filtrer par date (derni√®res X heures)
        cutoff_time = datetime.now() - timedelta(hours=hours_limit)
        recent_videos = []

        for entry in feed.entries:
            try:
                # Parser la date de publication
                pub_date = datetime(*entry.published_parsed[:6])

                # Garder seulement les vid√©os r√©centes
                if pub_date > cutoff_time:
                    video = {
                        "title": entry.title,
                        "url": entry.link,
                        "published": entry.published,
                        "channel": feed.feed.title
                        if hasattr(feed.feed, "title")
                        else extract_channel_name(channel_url),
                        "description": getattr(entry, "summary", ""),
                        "published_date": pub_date,
                    }
                    recent_videos.append(video)

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur parsing vid√©o : {e}")
                continue

        # Trier par date (plus r√©cent en premier)
        recent_videos.sort(key=lambda x: x["published_date"], reverse=True)
        return recent_videos

    except Exception as e:
        print(f"‚ùå Erreur RSS pour {channel_url} : {e}")
        return []


def get_video_id_from_url(video_url):
    """Extraire l'ID de vid√©o depuis une URL YouTube"""
    try:
        return video_url.split("watch?v=")[-1].split("&")[0]
    except (IndexError, AttributeError):
        return ""


def collect_videos_for_topic(topic, verbose=True):
    """Collecter toutes les vid√©os YouTube pour un topic via RSS"""
    all_videos = []
    
    if verbose:
        print(f"üì° R√©cup√©ration RSS pour {topic['name']} (7 derniers jours)...")

    for channel_url in topic["youtube_channels"]:
        channel_name = extract_channel_name(channel_url)
        
        if verbose:
            print(f"  üì∫ Analyse de {channel_name}...")

        videos = get_recent_videos_from_rss(channel_url, hours_limit=168)

        if videos:
            if verbose:
                print(f"    üìä {len(videos)} vid√©o(s) trouv√©e(s) sur 7 jours")
            
            # Ajouter les m√©tadonn√©es pour le traitement
            for video in videos:
                video["video_id"] = get_video_id_from_url(video["url"])
                video["channel_name"] = channel_name
            
            all_videos.extend(videos)
        else:
            if verbose:
                print("    ‚ö†Ô∏è Aucune vid√©o trouv√©e")

    # Trier par date de publication (plus r√©cent en premier)
    all_videos.sort(key=lambda x: x["published_date"], reverse=True)
    return all_videos


def test_rss_feeds(topics):
    """Tester les flux RSS pour tous les topics"""
    print("üß™ Test des flux RSS YouTube...")
    print("=" * 50)

    for topic in topics:
        print(f"\nüì∫ Topic : {topic['name']}")
        videos = collect_videos_for_topic(topic, verbose=True)

        if videos:
            print(f"‚úÖ {len(videos)} vid√©o(s) r√©cente(s) :")
            for video in videos[:3]:  # Afficher les 3 premi√®res
                print(f"  ‚Ä¢ {video['title']}")
                print(f"    Cha√Æne: {video['channel']} | Publi√©: {video['published']}")
                print(f"    URL: {video['url']}")
                print()
        else:
            print("‚ö†Ô∏è Aucune vid√©o r√©cente trouv√©e")