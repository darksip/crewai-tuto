#!/usr/bin/env python3
"""
SystÃ¨me de veille CrewAI - Version Simple
Configuration 100% dÃ©clarative via YAML
"""

import yaml
import os
import argparse
import requests
import feedparser
from datetime import datetime, timedelta
from pathlib import Path
import re
import subprocess

# Imports CrewAI
from crewai import Agent, Task, Crew
from crewai_tools import SerperDevTool

def load_config(config_file="veille.yaml"):
    """Charger la configuration YAML"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"âŒ Fichier {config_file} non trouvÃ©")
        return None
    except yaml.YAMLError as e:
        print(f"âŒ Erreur YAML : {e}")
        return None

def create_agents(config):
    """CrÃ©er les agents depuis la configuration"""
    agents = {}
    
    for name, agent_config in config['agents'].items():
        agent = Agent(
            role=agent_config['role'],
            goal=agent_config['goal'],
            backstory=agent_config['backstory'],
            verbose=True
        )
        agents[name] = agent
    
    return agents

def extract_channel_name(url):
    """Extraire le nom de la chaÃ®ne depuis l'URL YouTube"""
    try:
        if '@' in url:
            # Format: https://www.youtube.com/@Underscore_
            return url.split('@')[-1]
        elif '/c/' in url:
            # Format: https://www.youtube.com/c/Micode  
            return url.split('/c/')[-1]
        elif '/channel/' in url:
            # Format: https://www.youtube.com/channel/UCxxx
            return url.split('/channel/')[-1]
        else:
            # Fallback: prendre la derniÃ¨re partie aprÃ¨s /
            return url.split('/')[-1]
    except:
        return url  # Retourner l'URL si extraction Ã©choue

def get_channel_id_from_url(channel_url):
    """Obtenir l'ID de la chaÃ®ne depuis son URL YouTube - MÃ©thode curl/grep simple"""
    try:
        # Si c'est dÃ©jÃ  un ID de chaÃ®ne
        if channel_url.startswith('UC') and len(channel_url) == 24:
            return channel_url
            
        # Si c'est une URL avec /channel/
        if '/channel/' in channel_url:
            return channel_url.split('/channel/')[-1].split('?')[0]
        
        # Utiliser la mÃ©thode curl/grep qui fonctionne parfaitement
        import subprocess
        
        cmd = f'''curl -sL "{channel_url}" | grep -oE '("channelId"|"externalId"|"ownerChannelId"):"UC[-_0-9A-Za-z]{{22}}' | head -n1 | grep -oE 'UC[-_0-9A-Za-z]{{22}}' '''
        
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0 and result.stdout.strip():
            channel_id = result.stdout.strip()
            if channel_id.startswith('UC') and len(channel_id) == 24:
                return channel_id
        
        print(f"âš ï¸ Impossible de trouver l'ID pour {channel_url}")
        return None
        
    except Exception as e:
        print(f"âŒ Erreur extraction ID chaÃ®ne {channel_url}: {e}")
        return None

def get_recent_videos_from_rss(channel_url, hours_limit=24):
    """RÃ©cupÃ©rer les vidÃ©os rÃ©centes via RSS feed YouTube"""
    try:
        # Obtenir l'ID de la chaÃ®ne
        channel_id = get_channel_id_from_url(channel_url)
        if not channel_id:
            return []
        
        # Construire l'URL du flux RSS
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        
        # Parser le flux RSS
        feed = feedparser.parse(rss_url)
        
        if not feed.entries:
            print(f"âš ï¸ Aucune vidÃ©o trouvÃ©e dans le flux RSS pour {channel_url}")
            return []
        
        # Filtrer par date (derniÃ¨res X heures)
        cutoff_time = datetime.now() - timedelta(hours=hours_limit)
        recent_videos = []
        
        for entry in feed.entries:
            try:
                # Parser la date de publication
                pub_date = datetime(*entry.published_parsed[:6])
                
                # Garder seulement les vidÃ©os rÃ©centes
                if pub_date > cutoff_time:
                    video = {
                        "title": entry.title,
                        "url": entry.link,
                        "published": entry.published,
                        "channel": feed.feed.title if hasattr(feed.feed, 'title') else extract_channel_name(channel_url),
                        "description": getattr(entry, 'summary', ''),
                        "published_date": pub_date
                    }
                    recent_videos.append(video)
                    
            except Exception as e:
                print(f"âš ï¸ Erreur parsing vidÃ©o : {e}")
                continue
        
        # Trier par date (plus rÃ©cent en premier)
        recent_videos.sort(key=lambda x: x['published_date'], reverse=True)
        
        return recent_videos
        
    except Exception as e:
        print(f"âŒ Erreur RSS pour {channel_url} : {e}")
        return []

def get_all_youtube_videos(topic):
    """RÃ©cupÃ©rer toutes les vidÃ©os rÃ©centes pour un topic via RSS"""
    all_videos = []
    
    print(f"ğŸ“¡ RÃ©cupÃ©ration RSS pour {topic['name']}...")
    
    for channel_url in topic['youtube_channels']:
        channel_name = extract_channel_name(channel_url)
        print(f"  ğŸ“º Analyse de {channel_name}...")
        
        videos = get_recent_videos_from_rss(channel_url, hours_limit=72)  # 3 jours pour voir GosuCoder
        
        if videos:
            print(f"    âœ… {len(videos)} vidÃ©o(s) rÃ©cente(s) trouvÃ©e(s)")
            all_videos.extend(videos)
        else:
            print(f"    âš ï¸ Aucune vidÃ©o rÃ©cente")
    
    # Limiter au volume demandÃ© et trier par pertinence
    all_videos.sort(key=lambda x: x['published_date'], reverse=True)
    return all_videos[:topic['volume']]

def create_tasks(config, agents, topic):
    """CrÃ©er les tÃ¢ches pour un topic donnÃ©"""
    tasks = []
    
    # Extraire les noms des chaÃ®nes depuis les URLs
    channel_names = [extract_channel_name(url) for url in topic['youtube_channels']]
    
    # PrÃ©parer les variables pour le formatage
    variables = {
        'topic_name': topic['name'],
        'keywords': ', '.join(topic['keywords']),
        'youtube_channels': ', '.join(topic['youtube_channels']),  # URLs complÃ¨tes
        'volume': topic['volume'],
        'date': datetime.now().strftime('%d/%m/%Y')
    }
    
    # CrÃ©er les tÃ¢ches depuis la config
    for task_name, task_config in config['tasks'].items():
        task = Task(
            description=task_config['description'].format(**variables),
            expected_output=task_config['expected_output'],
            agent=agents[task_config['agent']]
        )
        tasks.append(task)
    
    return tasks

def save_synthesis(synthesis_content, topic_name, output_dir="syntheses"):
    """Sauvegarder la synthÃ¨se"""
    # CrÃ©er le rÃ©pertoire s'il n'existe pas
    Path(output_dir).mkdir(exist_ok=True)
    
    # Nom du fichier avec date
    date_str = datetime.now().strftime('%Y-%m-%d')
    filename = f"{output_dir}/synthese_{topic_name.replace(' ', '_')}_{date_str}.md"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(synthesis_content)
        print(f"âœ… SynthÃ¨se sauvÃ©e : {filename}")
        return filename
    except Exception as e:
        print(f"âŒ Erreur sauvegarde : {e}")
        return None

def run_veille_for_topic(config, agents, topic):
    """ExÃ©cuter la veille pour un topic"""
    print(f"\nğŸš€ Traitement du topic : {topic['name']}")
    
    # Ã‰tape 1: RÃ©cupÃ©rer les vidÃ©os rÃ©centes via RSS (plus fiable que Serper pour YouTube)
    recent_videos = get_all_youtube_videos(topic)
    
    # PrÃ©parer le contexte vidÃ©os pour les agents
    videos_context = ""
    if recent_videos:
        videos_context = "\n\nVIDÃ‰OS YOUTUBE RÃ‰CENTES TROUVÃ‰ES :\n"
        for i, video in enumerate(recent_videos[:5], 1):
            videos_context += f"{i}. **{video['title']}** ({video['channel']})\n"
            videos_context += f"   URL: {video['url']}\n"
            videos_context += f"   PubliÃ©: {video['published']}\n"
            if video['description']:
                videos_context += f"   Description: {video['description'][:100]}...\n"
            videos_context += "\n"
    
    # CrÃ©er les tÃ¢ches avec le contexte vidÃ©os
    tasks = create_tasks_with_video_context(config, agents, topic, videos_context)
    
    # Ajouter l'outil Serper aux agents (pour les articles seulement)
    search_tool = SerperDevTool()
    
    # Assigner l'outil Serper Ã  tous les agents
    for agent in agents.values():
        agent.tools = [search_tool]
    
    # CrÃ©er et lancer le crew
    crew = Crew(
        agents=list(agents.values()),
        tasks=tasks,
        verbose=True
    )
    
    try:
        # Lancer l'exÃ©cution
        print(f"âš¡ Lancement du crew pour {topic['name']} avec {len(recent_videos)} vidÃ©os RSS...")
        result = crew.kickoff()
        
        # Sauvegarder le rÃ©sultat
        output_dir = config.get('settings', {}).get('output_dir', 'syntheses')
        filename = save_synthesis(str(result), topic['name'], output_dir)
        
        print(f"âœ… Topic {topic['name']} terminÃ©")
        return filename
        
    except Exception as e:
        print(f"âŒ Erreur lors du traitement de {topic['name']} : {e}")
        return None

def create_tasks_with_video_context(config, agents, topic, videos_context):
    """CrÃ©er les tÃ¢ches avec le contexte vidÃ©os prÃ©-rÃ©cupÃ©rÃ©"""
    tasks = []
    
    # Extraire les noms des chaÃ®nes depuis les URLs
    channel_names = [extract_channel_name(url) for url in topic['youtube_channels']]
    
    # PrÃ©parer les variables pour le formatage
    variables = {
        'topic_name': topic['name'],
        'keywords': ', '.join(topic['keywords']),
        'youtube_channels': ', '.join(topic['youtube_channels']),
        'volume': topic['volume'],
        'date': datetime.now().strftime('%d/%m/%Y'),
        'videos_context': videos_context
    }
    
    # CrÃ©er les tÃ¢ches depuis la config
    for task_name, task_config in config['tasks'].items():
        description = task_config['description'].format(**variables)
        
        # Pour la tÃ¢che de synthÃ¨se, ajouter le contexte vidÃ©os
        if task_name == 'synthesize' and videos_context:
            description += videos_context
        
        task = Task(
            description=description,
            expected_output=task_config['expected_output'],
            agent=agents[task_config['agent']]
        )
        tasks.append(task)
    
    return tasks

def main():
    parser = argparse.ArgumentParser(description="Veille CrewAI Simple")
    parser.add_argument("--config", default="veille.yaml", help="Fichier de configuration")
    parser.add_argument("--topic", help="Topic spÃ©cifique Ã  traiter")
    parser.add_argument("--list-topics", action="store_true", help="Lister les topics")
    parser.add_argument("--test-rss", action="store_true", help="Tester les flux RSS YouTube")
    parser.add_argument("--dry-run", action="store_true", help="Mode simulation")
    
    args = parser.parse_args()
    
    # Banner
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            ğŸ¤– CrewAI Veille Simple               â•‘
â•‘                                                  â•‘
â•‘        Configuration 100% dÃ©clarative           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Charger la configuration
    config = load_config(args.config)
    if not config:
        return 1
    
    # Lister les topics
    if args.list_topics:
        print("ğŸ“‹ Topics configurÃ©s :")
        for topic in config['topics']:
            # Extraire les noms des chaÃ®nes pour l'affichage
            channel_names = [extract_channel_name(url) for url in topic['youtube_channels']]
            
            print(f"  â€¢ {topic['name']} (volume: {topic['volume']})")
            print(f"    Mots-clÃ©s : {', '.join(topic['keywords'])}")
            print(f"    ChaÃ®nes YouTube : {', '.join(channel_names)}")
            print()
        return 0
    
    # Tester les flux RSS YouTube
    if args.test_rss:
        print("ğŸ§ª Test des flux RSS YouTube...")
        print("=" * 50)
        
        for topic in config['topics']:
            print(f"\nğŸ“º Topic : {topic['name']}")
            videos = get_all_youtube_videos(topic)
            
            if videos:
                print(f"âœ… {len(videos)} vidÃ©o(s) rÃ©cente(s) :")
                for video in videos[:3]:  # Afficher les 3 premiÃ¨res
                    print(f"  â€¢ {video['title']}")
                    print(f"    ChaÃ®ne: {video['channel']} | PubliÃ©: {video['published']}")
                    print(f"    URL: {video['url']}")
                    print()
            else:
                print("âš ï¸ Aucune vidÃ©o rÃ©cente trouvÃ©e")
                
        return 0
    
    # Note: Les API keys sont gÃ©rÃ©es par Doppler automatiquement
    
    if args.dry_run:
        print("ğŸ§ª Mode simulation - Pas d'appels API")
        return 0
    
    # CrÃ©er les agents
    agents = create_agents(config)
    print(f"ğŸ­ {len(agents)} agents crÃ©Ã©s : {', '.join(agents.keys())}")
    
    # Traitement des topics
    topics_to_process = config['topics']
    
    # Filtrer par topic si spÃ©cifiÃ©
    if args.topic:
        topics_to_process = [t for t in topics_to_process if t['name'].lower() == args.topic.lower()]
        if not topics_to_process:
            print(f"âŒ Topic '{args.topic}' non trouvÃ©")
            return 1
    
    # Traiter chaque topic
    results = []
    for topic in topics_to_process:
        filename = run_veille_for_topic(config, agents, topic)
        if filename:
            results.append(filename)
    
    # RÃ©sumÃ©
    print(f"\nğŸ‰ Traitement terminÃ© !")
    print(f"ğŸ“Š {len(results)} synthÃ¨ses gÃ©nÃ©rÃ©es :")
    for filename in results:
        print(f"  ğŸ“„ {filename}")
    
    return 0

if __name__ == "__main__":
    exit(main())